import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import joblib

print("Starting model training process...")

# --- 1. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---
try:
    # ÙŠÙ‚Ø±Ø£ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ Ø£Ù†Ø´Ø£Ù†Ø§Ù‡ Ø³Ø§Ø¨Ù‚Ù‹Ø§
    dataset = pd.read_csv('tasks_dataset.csv')
    X = dataset['task_description']
    y = dataset['priority']
    print(f"ğŸ“„ Dataset loaded with {len(dataset)} samples.")
except FileNotFoundError:
    print("âŒ Error: 'tasks_dataset.csv' not found!")
    print("â¡ï¸ Please run 'generate_data.py' first to create the dataset.")
    exit()  # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# --- 2. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù€ Vectorizer ---
# Ù‡Ø°Ø§ Ø§Ù„ÙƒØ§Ø¦Ù† ÙŠØ­ÙˆÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… ÙŠØ³ØªØ·ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‡Ù…Ù‡Ø§
vectorizer = TfidfVectorizer()
X_vectorized = vectorizer.fit_transform(X)
print("Vectorizer has been trained.")

# --- 3. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
# Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ© Ø§Ù„ØªØµÙ†ÙŠÙ
model = MultinomialNB()
model.fit(X_vectorized, y)
print("Model has been trained.")

# --- 4. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ Vectorizer ÙÙŠ Ù…Ù„ÙØ§Øª ---
# Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªÙŠ ØªÙ†Ø´Ø¦ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ÙŠØ­ØªØ§Ø¬Ù‡Ø§ app.py
joblib.dump(model, 'task_priority_model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')

print("\nâœ… Success! Model and vectorizer have been saved as:")
print("- task_priority_model.pkl")
print("- vectorizer.pkl")
